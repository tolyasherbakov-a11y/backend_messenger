version: "3.9"

x-health-defaults: &health_defaults
  interval: 10s
  timeout: 3s
  retries: 5
  start_period: 10s

networks:
  backend:
    driver: bridge

volumes:
  pgdata:
  minio-data:
  nginx-cache:

services:
  postgres:
    image: postgres:16-alpine
    container_name: backend-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DB_NAME:-app}
      POSTGRES_USER: ${DB_USER:-app}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-app}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --lc-collate=C --lc-ctype=C"
    command: >
      postgres -c shared_buffers=256MB
               -c work_mem=32MB
               -c maintenance_work_mem=128MB
               -c effective_cache_size=768MB
               -c max_connections=200
               -c wal_level=replica
               -c max_wal_size=2GB
               -c checkpoint_timeout=10min
               -c statement_timeout=5000
               -c idle_in_transaction_session_timeout=5000
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-app} -d ${DB_NAME:-app}"]
      <<: *health_defaults
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      # Открой порт только в dev. В проде лучше оставить внутренним.
      - "5432:5432"
    networks:
      - backend

  redis:
    image: redis:7-alpine
    container_name: backend-redis
    restart: unless-stopped
    command: ["redis-server", "--save", "", "--appendonly", "no", "--maxmemory-policy", "allkeys-lru"]
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep -q PONG"]
      <<: *health_defaults
    networks:
      - backend
    ports:
      - "6379:6379"

  minio:
    image: quay.io/minio/minio:RELEASE.2025-01-20T00-00-00Z
    container_name: backend-minio
    restart: unless-stopped
    command: ["server", "/data", "--console-address", ":9001"]
    environment:
      MINIO_ROOT_USER: ${S3_ACCESS_KEY:-minioadmin}
      MINIO_ROOT_PASSWORD: ${S3_SECRET_KEY:-minioadmin}
      MINIO_REGION_NAME: ${S3_REGION:-us-east-1}
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:9000/minio/health/ready >/dev/null"]
      <<: *health_defaults
    ports:
      - "9000:9000" # API
      - "9001:9001" # Console
    networks:
      - backend

  clamav:
    image: clamav/clamav:1.3
    container_name: backend-clamav
    restart: unless-stopped
    environment:
      # Базовые обновления сигнатур выполняются при старте
      CLAMAV_NO_FRESHCLAMD: "false"
    healthcheck:
      test: ["CMD-SHELL", "printf 'PING\\n' | nc -w 2 127.0.0.1 3310 | grep -q PONG"]
      <<: *health_defaults
    networks:
      - backend
    ports:
      - "3310:3310"

  # ⬇️ API и воркеры будут собраны из соответствующих подкаталогов. Добавляем сразу полноценные сервисы.
  api:
    build:
      context: ../apps/api
      dockerfile: Dockerfile
    container_name: backend-api
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      NODE_ENV: production
      PORT: 8080
      DB_URL: postgres://${DB_USER:-app}:${DB_PASSWORD:-app}@postgres:5432/${DB_NAME:-app}
      REDIS_URL: redis://redis:6379
      S3_ENDPOINT: http://minio:9000
      S3_REGION: ${S3_REGION:-us-east-1}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY:-minioadmin}
      S3_SECRET_KEY: ${S3_SECRET_KEY:-minioadmin}
      S3_BUCKET_PRIVATE: ${S3_BUCKET_PRIVATE:-media}
      S3_BUCKET_PUBLIC: ${S3_BUCKET_PUBLIC:-public}
      CLAMD_HOST: clamav
      CLAMD_PORT: 3310
      PUBLIC_URL: http://localhost
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      clamav:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8080/readyz >/dev/null"]
      <<: *health_defaults
    networks:
      - backend

  worker-video-transcode:
    build:
      context: ../apps/workers/video-transcode
      dockerfile: Dockerfile
    container_name: backend-worker-video
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      NODE_ENV: production
      DB_URL: postgres://${DB_USER:-app}:${DB_PASSWORD:-app}@postgres:5432/${DB_NAME:-app}
      REDIS_URL: redis://redis:6379
      S3_ENDPOINT: http://minio:9000
      S3_REGION: ${S3_REGION:-us-east-1}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY:-minioadmin}
      S3_SECRET_KEY: ${S3_SECRET_KEY:-minioadmin}
      S3_BUCKET_PRIVATE: ${S3_BUCKET_PRIVATE:-media}
      VIDEO_KEYINT_SEC: ${VIDEO_KEYINT_SEC:-2}
      FFMPEG_MAX_INPUT_MB: ${FFMPEG_MAX_INPUT_MB:-2048}
    depends_on:
      api:
        condition: service_healthy
    networks:
      - backend

  worker-image-variants:
    build:
      context: ../apps/workers/image-variants
      dockerfile: Dockerfile
    container_name: backend-worker-image
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      NODE_ENV: production
      DB_URL: postgres://${DB_USER:-app}:${DB_PASSWORD:-app}@postgres:5432/${DB_NAME:-app}
      REDIS_URL: redis://redis:6379
      S3_ENDPOINT: http://minio:9000
      S3_REGION: ${S3_REGION:-us-east-1}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY:-minioadmin}
      S3_SECRET_KEY: ${S3_SECRET_KEY:-minioadmin}
      S3_BUCKET_PRIVATE: ${S3_BUCKET_PRIVATE:-media}
      SHARP_CONCURRENCY: ${SHARP_CONCURRENCY:-2}
      IMG_MAX_INPUT_MB: ${IMG_MAX_INPUT_MB:-50}
    depends_on:
      api:
        condition: service_healthy
    networks:
      - backend

  worker-antivirus:
    build:
      context: ../apps/workers/media-antivirus
      dockerfile: Dockerfile
    container_name: backend-worker-antivirus
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      NODE_ENV: production
      DB_URL: postgres://${DB_USER:-app}:${DB_PASSWORD:-app}@postgres:5432/${DB_NAME:-app}
      REDIS_URL: redis://redis:6379
      CLAMD_HOST: clamav
      CLAMD_PORT: 3310
    depends_on:
      api:
        condition: service_healthy
      clamav:
        condition: service_healthy
    networks:
      - backend

  worker-metadata:
    build:
      context: ../apps/workers/media-metadata
      dockerfile: Dockerfile
    container_name: backend-worker-metadata
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      NODE_ENV: production
      DB_URL: postgres://${DB_USER:-app}:${DB_PASSWORD:-app}@postgres:5432/${DB_NAME:-app}
      REDIS_URL: redis://redis:6379
      S3_ENDPOINT: http://minio:9000
      S3_REGION: ${S3_REGION:-us-east-1}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY:-minioadmin}
      S3_SECRET_KEY: ${S3_SECRET_KEY:-minioadmin}
      S3_BUCKET_PRIVATE: ${S3_BUCKET_PRIVATE:-media}
    depends_on:
      api:
        condition: service_healthy
    networks:
      - backend

  worker-media-gc:
    build:
      context: ../apps/workers/media-gc
      dockerfile: Dockerfile
    container_name: backend-worker-gc
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      NODE_ENV: production
      DB_URL: postgres://${DB_USER:-app}:${DB_PASSWORD:-app}@postgres:5432/${DB_NAME:-app}
      REDIS_URL: redis://redis:6379
      S3_ENDPOINT: http://minio:9000
      S3_REGION: ${S3_REGION:-us-east-1}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY:-minioadmin}
      S3_SECRET_KEY: ${S3_SECRET_KEY:-minioadmin}
      S3_BUCKET_PRIVATE: ${S3_BUCKET_PRIVATE:-media}
    depends_on:
      api:
        condition: service_healthy
    networks:
      - backend

  nginx:
    image: nginx:1.27-alpine
    container_name: backend-nginx
    restart: unless-stopped
    depends_on:
      api:
        condition: service_healthy
    ports:
      - "80:80"
      # Для TLS добавьте сертификаты и раскройте порт:
      # - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - nginx-cache:/var/cache/nginx
      # Для TLS положите cert/key в ./nginx/certs/ и раскомментируйте строки в nginx.conf
      # - ./nginx/certs:/etc/nginx/certs:ro
    networks:
      - backend

  search-indexer:
    build:
      context: ../apps/workers/search-indexer
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      DB_URL: postgres://app:app@postgres:5432/app
      REDIS_URL: redis://redis:6379
      OS_NODE: http://opensearch:9200
      OS_USERNAME: ${OS_USERNAME:-}
      OS_PASSWORD: ${OS_PASSWORD:-}
      OS_INDEX_PREFIX: app
      STREAM_INDEX: q:search.index
      STREAM_DELETE: q:search.delete
      GROUP: g:search
      CONCURRENCY: 2
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      opensearch:
        condition: service_started
    networks: [ backend ]
  
  opensearch:
    image: opensearchproject/opensearch:2.12.0
    container_name: backend-opensearch
    environment:
      - discovery.type=single-node
      - plugins.security.disabled=true
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:9200 >/dev/null"]
      interval: 10s
      timeout: 3s
      retries: 10
    ports:
      - "9200:9200"
    networks: [ backend ]
